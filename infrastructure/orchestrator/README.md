# **Temporal Orchestrator â€” README**

## 1. Overview

This directory contains a **Temporal.io orchestration system** for managing containerized services in the LLM chatbot infrastructure.

**Components:**

* **Activities** â€“ Individual operations (e.g., container start/stop, monitoring).
* **Workflows** â€“ Orchestration logic to coordinate activities.
* **Workers** â€“ Poll task queues and execute workflows/activities.
* **Temporal Server** â€“ Manages state and workflow durability.
* **Trigger / Stop scripts** â€“ Start or terminate workflows, organized per service.

---

## 2. Folder Structure

```
temporal-orchestrator/
â”‚
â”œâ”€â”€ activities/
â”‚   â”œâ”€â”€ ai_proxy_container_activity.py
â”‚   â”œâ”€â”€ my_new_activity.py           # Example new activity
â”‚   â””â”€â”€ common_activity/
â”‚       â”œâ”€â”€ start_grafana_activity.py
â”‚       â”œâ”€â”€ configure_grafana_activity.py
â”‚       â”œâ”€â”€ loki_activity.py
â”‚       â”œâ”€â”€ otel_activity.py
â”‚       â”œâ”€â”€ promotheus_activity.py
â”‚       â””â”€â”€ promtail_activity.py
â”‚
â”œâ”€â”€ dynamicconfig/
â”‚   â””â”€â”€ development-sql.yaml
â”‚
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ logging_pipeline_workflow.py
â”‚   â””â”€â”€ my_new_workflow.py           # Example new workflow
â”‚
â”œâ”€â”€ workers/
â”‚   â”œâ”€â”€ logging_pipeline_worker.py
â”‚   â””â”€â”€ my_new_worker.py             # Example new worker
â”‚
â”œâ”€â”€ trigger/
â”‚   â””â”€â”€ ai_proxy_container/          # Example service folder
â”‚       â”œâ”€â”€ start.py
â”‚       â””â”€â”€ stop.py
â”‚   â””â”€â”€ knowledge_graph/             # Example service folder
â”‚       â”œâ”€â”€ start.py
â”‚       â””â”€â”€ stop.py
â”‚
â”œâ”€â”€ temporal-orchestrator-compose.yaml
â””â”€â”€ README.md
```

> **Note:** Each new service gets its own folder under `trigger/` with its `start.py` and `stop.py` scripts.

---

## 3. Adding a New Activity

**Path:** `activities/my_new_activity.py`

```python
from temporalio import activity
import asyncio

@activity.defn
async def my_new_activity(arg: str) -> str:
    """Minimal new activity"""
    await asyncio.sleep(0.1)
    return f"done:{arg}"
```

---

## 4. Adding a New Workflow

**Path:** `workflows/my_new_workflow.py`

```python
from datetime import timedelta
from temporalio import workflow
from temporalio.common import RetryPolicy

@workflow.defn
class MyNewWorkflow:
    @workflow.run
    async def run(self, param: str) -> str:
        from activities.my_new_activity import my_new_activity

        result = await workflow.execute_activity(
            my_new_activity,
            param,
            start_to_close_timeout=timedelta(minutes=2),
            retry_policy=RetryPolicy(
                maximum_attempts=3,
                initial_interval=timedelta(seconds=10),
            ),
        )
        return result
```

---

## 5. Adding a New Worker (Independent)

**Path:** `workers/my_new_worker.py`

```python
import asyncio
from temporalio.client import Client
from temporalio.worker import Worker
from workflows.my_new_workflow import MyNewWorkflow
from activities.my_new_activity import my_new_activity

async def main():
    client = await Client.connect("localhost:7233")
    worker = Worker(
        client,
        task_queue="my-new-task-queue",
        workflows=[MyNewWorkflow],
        activities=[my_new_activity]
    )
    await worker.run()

if __name__ == "__main__":
    asyncio.run(main())
```

> No edits to existing workers are required.

---

## 6. Trigger Script for a Service

**Path:** `trigger/knowledge_graph/start.py`

```python
import asyncio
from temporalio.client import Client
from workflows.my_new_workflow import MyNewWorkflow

async def main():
    client = await Client.connect("localhost:7233")
    result = await client.execute_workflow(
        MyNewWorkflow.run,
        "input-value",
        id="knowledge_graph_1",
        task_queue="my-new-task-queue",
    )
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 7. Stop Script for a Service

**Path:** `trigger/knowledge_graph/stop.py`

```python
import asyncio
from temporalio.client import Client

async def main():
    client = await Client.connect("localhost:7233")
    await client.terminate_workflow("knowledge_graph_1", reason="manual stop")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 8. Commands

### Start Temporal Infrastructure

```bash
cd infrastructure/orchestrator
docker-compose -f temporal-orchestrator-compose.yaml down -v
docker system prune -f
docker-compose -f temporal-orchestrator-compose.yaml up -d
cd ../..
```

### Verify Services

```bash
docker ps
curl http://0.0.0.0:8080/namespaces/default/workflows
docker exec temporal-postgresql psql -U temporal -d temporal -c "SELECT 1;"
```

### Start New Worker

```bash
cd workers
python3 my_new_worker.py
```

### Trigger Service Workflow

```bash
cd trigger/knowledge_graph
python3 start.py
```

### Stop Service Workflow

```bash
cd trigger/knowledge_graph
python3 stop.py
```

### Stop Infrastructure

```bash
docker-compose -f temporal-orchestrator-compose.yaml down
```

---

## 9. Visual Pipeline (for Knowledge Graph Service)

```
[Trigger Script]         trigger/knowledge_graph/start.py
       â”‚
       â–¼
[Temporal Server]         localhost:7233
       â”‚
       â–¼
[Worker]                  workers/my_new_worker.py
       â”‚
       â–¼
[Workflow Execution]      workflows/my_new_workflow.py
       â”‚
       â””â”€â–º calls activities/my_new_activity.py
       â”‚
       â–¼
[Results / State]         Temporal DB (Postgres)
       â”‚
       â–¼
[Web UI / Logs]           http://localhost:8080
```

# ğŸŒ² **MASTER EXECUTION + RELATIONSHIP TREE**

```
PIPELINE_SYSTEM
â”‚
â”œâ”€ CONTROL_PLANE  (META: decisions, identity, routing, meaning)
â”‚   â”‚
â”‚   â”œâ”€ WorkflowConfig  (meta config)
â”‚   â”‚     â”‚
â”‚   â”‚     â”œâ”€ service_name        = logical pipeline identity
â”‚   â”‚     â”œâ”€ workflow_name       = workflow class to start
â”‚   â”‚     â”œâ”€ task_queue          = execution route (auto: <service_name>-queue)
â”‚   â”‚     â”œâ”€ temporal_host       = cluster connection target
â”‚   â”‚     â””â”€ web_ui_url          = observation URL (optional / meta only)
â”‚   â”‚
â”‚   â”œâ”€ PipelineExecutor  (meta orchestrator)
â”‚   â”‚     â”‚
â”‚   â”‚     â”œâ”€ reads WorkflowConfig
â”‚   â”‚     â”œâ”€ connects to temporal_host
â”‚   â”‚     â””â”€ start_workflow(
â”‚   â”‚           workflow_name,
â”‚   â”‚           arg = service_name,
â”‚   â”‚           task_queue = task_queue
â”‚   â”‚        )
â”‚   â”‚
â”‚   â””â”€ Workflow State Machine (meta logic)
â”‚         â”‚
â”‚         â””â”€ Describes *order* of operations (not actual work):
â”‚                start_opentelemetry â†’ start_loki â†’ start_grafana â†’ return result
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ TRAVEL ACROSS NETWORK
                            (Temporal API call)
```

---

# ğŸ›°ï¸ **TEMPORAL ROUTING LAYER (Control â†’ Execution Bridge)**

```
TEMPORAL_SERVER
â”‚
â”œâ”€ Receives workflow start request
â”‚
â”œâ”€ Creates Workflow Execution History (META: deterministic timeline)
â”‚
â””â”€ SCHEDULE_WORKFLOW_TASK
       â”‚
       â””â”€ Route by queue:
           task_queue = "<service_name>-queue"
```

**This is the critical relationship:**

```
WorkflowConfig.task_queue  MUST MATCH  WorkerConfig.task_queue
```

This is the **binding point** of the system.

---

# âš™ï¸ **DATA_PLANE (Execution Happens Here)**

```
DATA_PLANE
â”‚
â”œâ”€ WorkerConfig  (meta execution environment description)
â”‚   â”‚
â”‚   â”œâ”€ host           = temporal endpoint
â”‚   â”œâ”€ task_queue     = execution queue (same as WorkflowConfig)
â”‚   â”œâ”€ namespace      = logical tenant
â”‚   â””â”€ max_concurrency  (optional runtime tuning)
â”‚
â”œâ”€ Worker (runtime executor process)
â”‚   â”‚
â”‚   â”œâ”€ Registers:
â”‚   â”‚     - Workflows: [LogsPipelineWorkflow]
â”‚   â”‚     - Activities: [start_loki, start_grafana, etc]
â”‚   â”‚
â”‚   â””â”€ Listens on task_queue
â”‚         â”‚
â”‚         â””â”€ When workflow tasks arrive â†’ run workflow logic step-by-step
â”‚
â””â”€ Activity Executor (real work happens here)
      â”‚
      â”œâ”€ start_opentelemetry_collector(service_name)
      â”œâ”€ start_loki_activity(service_name)
      â”œâ”€ start_grafana_activity(service_name)
      â””â”€ etc...
      â”‚
      â””â”€ These functions produce **real side-effects**:
            - Launch containers
            - Configure services
            - Apply setup changes
```

---

# ğŸ›ï¸ **WORKFLOW EXECUTION PLAY-BY-PLAY**

```
Workflow (META: high-level sequence)
â”‚
â””â”€ Step 1: schedule activity: start_opentelemetry_collector
      â”‚
      â””â”€ Temporal routes â†’ Worker â†’ Activity executes (real work)
             â”‚
             â””â”€ Return OK â†’ Workflow proceeds

â””â”€ Step 2: schedule activity: start_loki_activity
      â”‚
      (same dispatch-execute-return pattern)

â””â”€ Step 3: schedule activity: start_grafana_activity

â””â”€ Workflow returns: "Logs pipeline fully configured"
```

---

# âš¡ RELATIONSHIP CLASSIFICATION (Final clarity)

| Relationship                                        | Direction    | Type              | Explanation                                   |
| --------------------------------------------------- | ------------ | ----------------- | --------------------------------------------- |
| PipelineExecutor â†’ WorkflowConfig                   | uses         | META              | Executor reads config to know *what to start* |
| PipelineExecutor â†’ Temporal Server                  | commands     | CONTROL           | Executor tells Temporal to create workflow    |
| WorkflowConfig.task_queue â†” WorkerConfig.task_queue | binding link | ROUTING           | Ensures workflow tasks and worker match       |
| Temporal Server â†’ Worker                            | dispatches   | EXECUTION ROUTING | Server delivers tasks to worker queue         |
| Worker â†’ Workflow                                   | hosts        | EXECUTION CONTEXT | Worker runs workflow state machine            |
| Workflow â†’ Activities                               | delegates    | TASK EXECUTION    | Workflow requests work, activities do work    |
| Activities â†’ External Systems                       | acts         | REAL EFFECT       | System state changes happen here              |

---
